{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project: AI Agents for Lifelong Learning  \n",
    "\n",
    "## The Problem  \n",
    "\n",
    "Lifelong learning depends not just on access to information, but on consistent exposure to **relevant, up-to-date content** that aligns with individual interests and contributes meaningfully to personal and professional growth.  \n",
    "\n",
    "While information is abundant, there’s no solution that effectively curates **up-to-date, relevant content** tailored to evolving interests.  \n",
    "\n",
    "I’ve faced this pain point firsthand. Staying current with newsletters, research updates, and niche discussions is overwhelming and inefficient. \n",
    "\n",
    "This project addresses a critical gap: leveraging the constant flow of new content to accelerate learning in a way that is personalized, actionable, and aligned with long-term growth.  \n",
    "\n",
    "\n",
    "\n",
    "## The Solution  \n",
    "\n",
    "This project introduces a **multi-agent system** designed to act as a learning companion, curating and delivering content that supports continuous, personalized education. Using **Crew AI**, we build a system that:  \n",
    "\n",
    "1. **Aggregates Content**: Dynamically retrieves articles, memos, and updates from diverse, high-quality sources like Hacker News and professional newsletters.  \n",
    "2. **Filters for Relevance**: Identifies the most pertinent content aligned with user-defined learning goals and interests.  \n",
    "3. **Summarizes for Precision**: Provides concise overviews, enabling users to quickly assess the value of each piece while linking to the original material for deeper exploration.  \n",
    "\n",
    "## How It Works  \n",
    "\n",
    "The system leverages the synergy of **AI agents** and **Large Language Models (LLMs)** to ensure relevance and adaptability:  \n",
    "\n",
    "- **Fetcher Agent**: Collects content from predefined sources, ensuring a consistent and diverse stream of information.  \n",
    "- **Filter Agent**: Evaluates and prioritizes content based on relevance to user preferences and learning goals.  \n",
    "- **Summarizer Agent**: Distills selected content into concise summaries, retaining key insights for quick and effective understanding.  \n",
    "- **Notifier Agent**: Logs curated content and sends summaries to the user via WhatsApp for seamless accessibility.  \n",
    "\n",
    "\n",
    "## Impact on Lifelong Learning  \n",
    "\n",
    "This system supports lifelong learning by:  \n",
    "1. **Promoting Focus**: Reducing noise and information overload by prioritizing relevant content.  \n",
    "2. **Encouraging Exploration**: Suggesting diverse sources and materials tailored to specific interests.  \n",
    "3. **Adapting Over Time**: Growing alongside the user’s learning journey, offering increasingly precise recommendations.  \n",
    "\n",
    "## Evaluation Metrics  \n",
    "\n",
    "The success of this project will be measured by:  \n",
    "1. **Relevance Accuracy**: At least 90% of recommendations align with user interests.  \n",
    "2. **Engagement**: Users interact with >80% of delivered content through summaries or full articles.  \n",
    "3. **Feedback Adaptability**: The system demonstrates a measurable improvement in relevance precision over time.  \n",
    "\n",
    "---\n",
    "\n",
    "## Final Goal  \n",
    "\n",
    "To create a precise, adaptable, and user-focused system that empowers lifelong learners by seamlessly integrating relevant, high-quality content into their daily routines.  \n",
    "\n",
    "This project emphasizes the transformative power of AI in shaping learning habits, demonstrating that with the right tools, lifelong learning can become not just a goal, but a natural and effortless part of life.  \n",
    "\n",
    "---\n",
    "\n",
    "### Repository  \n",
    "[ai-agents-crewAI](https://github.com/felipebpl/ai-agents-crewAI)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'source': 'https://news.ycombinator.com/', 'summary': \"- **Title**: Hacker News Overview\\n- **Key Takeaway**: Hacker News posts cover a variety of topics, including technology, programming, science, and current events, with user engagement varying across posts.\\n- **Why It Matters**: Staying updated on these discussions can provide insights into trending topics, technological developments, and potential business opportunities.\\n- **Details**: \\n   - Erlang hot code updates, Open Riak, and Python's object-oriented programming are among the trending programming topics.\\n   - Discussions on artificial intelligence breakthroughs highlight the importance of deep learning.\\n   - There's a user-created black hole simulation for iPhone, indicating interest in astrophysics and app development.\\n   - Questions about traditional coding practices, like the 80 character line\"}, {'source': 'https://www.paulgraham.com/articles.html', 'summary': '- **Title**: Various Essays and Articles\\n- **Key Takeaway**: A collection of essays and articles encompassing a broad range of topics including work ethics, startups, wealth, ideas, and innovation among others.\\n- **Why It Matters**: These writings offer valuable insights and perspectives on various aspects of work, entrepreneurship, innovation, and personal development that can contribute to strategic decision-making and personal growth.\\n- **Details**: \\n    - Essays such as \"How to Do Great Work\", \"Having Kids\", \"How to Lose Time and Money\" provide guidance on productivity, personal choices and financial management.\\n    - Topics like \"Startup = Growth\", \"Black Swan Farming\", \"How to Get Startup Ideas\" offer insights into startup dynamics and innovation.\\n'}]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import logging\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from typing import List, Dict\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Validate environment variables\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not OPENAI_API_KEY:\n",
    "    raise ValueError(\"Missing 'OPENAI_API_KEY' in environment variables.\")\n",
    "\n",
    "# WHATSAPP_API_TOKEN = os.getenv(\"WHATSAPP_API_TOKEN\")\n",
    "# USER_PHONE = os.getenv(\"USER_PHONE\")\n",
    "\n",
    "# if not WHATSAPP_API_TOKEN or not USER_PHONE:\n",
    "#     raise ValueError(\"Missing 'WHATSAPP_API_TOKEN' or 'USER_PHONE' in environment variables.\")\n",
    "\n",
    "OPENAI_API_URL = \"https://api.openai.com/v1/chat/completions\"\n",
    "WHATSAPP_API_URL = \"https://your-whatsapp-api-endpoint\"\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', datefmt='%d-%b-%y %H:%M:%S')\n",
    "\n",
    "# Parse html content\n",
    "def preprocess_html_to_text(html_content: str) -> str:\n",
    "    \"\"\"\n",
    "    Preprocesses HTML content by extracting clean text for AI summarization.\n",
    "\n",
    "    Args:\n",
    "        html_content (str): Raw HTML content.\n",
    "\n",
    "    Returns:\n",
    "        str: Cleaned and readable plain text.\n",
    "    \"\"\"\n",
    "    # Parse HTML with BeautifulSoup\n",
    "    soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "\n",
    "    # Extract and join visible text\n",
    "    clean_text = ' '.join(soup.stripped_strings)\n",
    "\n",
    "    return clean_text\n",
    "\n",
    "\n",
    "# Utility function for OpenAI API\n",
    "def generate_summary(prompt: str, text: str) -> str:\n",
    "    cleaned_text = preprocess_html_to_text(text)\n",
    "    \n",
    "    headers = {\"Authorization\": f\"Bearer {OPENAI_API_KEY}\", \"Content-Type\": \"application/json\"}\n",
    "    payload = {\n",
    "        \"model\": \"gpt-4\",\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": prompt},\n",
    "            {\"role\": \"user\", \"content\": cleaned_text}\n",
    "        ],\n",
    "        \"max_tokens\": 150,\n",
    "        \"temperature\": 0.7\n",
    "    }\n",
    "    response = requests.post(OPENAI_API_URL, headers=headers, json=payload)\n",
    "    response.raise_for_status()\n",
    "    response_data = response.json()\n",
    "    return response_data['choices'][0]['message']['content']\n",
    "\n",
    "\n",
    "# Agents\n",
    "class FetcherAgent:\n",
    "    def __init__(self, sources: List[str]):\n",
    "        self.sources = sources\n",
    "\n",
    "    def fetch_content(self) -> List[Dict[str, str]]:\n",
    "        logging.info(\"Fetching content from sources.\")\n",
    "        results = []\n",
    "        for source in self.sources:\n",
    "            try:\n",
    "                logging.info(f\"Scraping content from: {source}\")\n",
    "                response = requests.get(source)\n",
    "                response.raise_for_status()\n",
    "                results.append({\"source\": source, \"content\": response.text})\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error scraping {source}: {e}\")\n",
    "        return results\n",
    "\n",
    "\n",
    "class FilterAgent:\n",
    "    def __init__(self, keywords: List[str]):\n",
    "        self.keywords = keywords\n",
    "\n",
    "    def filter_content(self, fetched_content: List[Dict[str, str]]) -> List[Dict[str, str]]:\n",
    "        logging.info(\"Filtering content based on keywords.\")\n",
    "        filtered_results = [\n",
    "            item for item in fetched_content\n",
    "            if any(keyword.lower() in item[\"content\"].lower() for keyword in self.keywords)\n",
    "        ]\n",
    "        logging.info(f\"Filtered {len(filtered_results)} items.\")\n",
    "        return filtered_results\n",
    "\n",
    "\n",
    "class SummarizerAgent:\n",
    "    def __init__(self, prompt: str):\n",
    "        self.prompt = prompt\n",
    "\n",
    "    def summarize_content(self, filtered_content: List[Dict[str, str]]) -> List[Dict[str, str]]:\n",
    "        logging.info(\"Summarizing content.\")\n",
    "        summarized_results = []\n",
    "        for item in filtered_content:\n",
    "            try:\n",
    "                summary = generate_summary(self.prompt, item[\"content\"])\n",
    "                summarized_results.append({\"source\": item[\"source\"], \"summary\": summary})\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error summarizing content from {item['source']}: {e}\")\n",
    "        return summarized_results\n",
    "\n",
    "\n",
    "class NotifierAgent:\n",
    "    def __init__(self):\n",
    "        self.api_url = WHATSAPP_API_URL\n",
    "        self.api_token = WHATSAPP_API_TOKEN\n",
    "        self.user_phone = USER_PHONE\n",
    "\n",
    "    def send_notifications(self, summaries: List[Dict[str, str]]):\n",
    "        logging.info(\"Logging and sending notifications.\")\n",
    "        for summary in summaries:\n",
    "            message = f\"Source: {summary['source']}\\nSummary:\\n{summary['summary']}\"\n",
    "            logging.info(message)\n",
    "            self._send_whatsapp_message(message)\n",
    "\n",
    "    def _send_whatsapp_message(self, message: str):\n",
    "        payload = {\n",
    "            \"to\": self.user_phone,\n",
    "            \"type\": \"text\",\n",
    "            \"text\": {\"body\": message}\n",
    "        }\n",
    "        headers = {\n",
    "            \"Authorization\": f\"Bearer {self.api_token}\",\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        }\n",
    "        try:\n",
    "            response = requests.post(self.api_url, json=payload, headers=headers)\n",
    "            response.raise_for_status()\n",
    "            logging.info(\"Message sent successfully.\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error sending message: {e}\")\n",
    "\n",
    "# Main Execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Define user preferences\n",
    "    sources = [\n",
    "        \"https://news.ycombinator.com/\",\n",
    "        \"https://www.paulgraham.com/articles.html\"\n",
    "    ]\n",
    "    keywords = [\"AI\", \"machine learning\", \"venture capital\"]\n",
    "    prompt = \"\"\"\n",
    "    You are a specialized assistant for a busy founder. Your goal is to distill the essence of the following text into a concise and actionable summary. Focus on extracting the most relevant and insightful points that contribute to strategic decision-making, personal growth, or learning essential trends. Avoid fluff or generalities. Write simply and clearly, as if explaining to a peer.\n",
    "\n",
    "    Use the following structure:\n",
    "    - **Title**: Source title.\n",
    "    - **Key Takeaway**: One-sentence summary.\n",
    "    - **Why It Matters**: Brief significance.\n",
    "    - **Details**: Bullet points with essential context.\n",
    "\n",
    "    Text:\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize agents\n",
    "    fetcher = FetcherAgent(sources)\n",
    "    filter_agent = FilterAgent(keywords)\n",
    "    summarizer = SummarizerAgent(prompt)\n",
    "    # notifier = NotifierAgent()\n",
    "\n",
    "    # Run pipeline\n",
    "    fetched_content = fetcher.fetch_content()\n",
    "    filtered_content = filter_agent.filter_content(fetched_content)\n",
    "    summarized_content = summarizer.summarize_content(filtered_content)\n",
    "    # notifier.send_notifications(summarized_content)\n",
    "    print(summarized_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
